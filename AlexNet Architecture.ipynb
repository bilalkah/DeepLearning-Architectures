{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://neurohive.io/wp-content/uploads/2018/10/AlexNet-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagram that will help you in writing code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://d3i71xaburhd42.cloudfront.net/b57e6468740d9320f3f14c6079168b8e21366416/11-Figure14-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are implementing the AlexNet code on oxflower17 dataset which is available in tflearn package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: For tflearn we need tensorflow version== 1.14\n",
    "\n",
    "\n",
    "### Steps to be performed in Anaconda Prompt\n",
    "\n",
    "#### Creating environment\n",
    ">> conda create -n env python==3.6.8\n",
    "\n",
    "### Installing tensorflow==1.14\n",
    ">> conda install tensorflow==1.14\n",
    "\n",
    "### Installing keras==2.3.1\n",
    ">> conda install keras==2.3.1\n",
    "\n",
    "### Installing tflearn\n",
    ">> conda install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impoting tensorflow\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing keras\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing other libraries\n",
    "from tflearn.datasets import oxflower17 # Importing the datasets from tflearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dropout, MaxPooling2D, BatchNormalization, Activation, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the oxflower17 dataset- It has 1360 images divided into 17 categories\n",
    "X, Y = oxflower17.load_data(r'C:\\Users\\khand\\Downloads\\Deep_Learning\\Deep Learning3\\Going depper with Convolutions\\Architectures codes\\17flowers', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1360, 224, 224, 3), (1360, 17))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of X and Y\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 54, 54, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 54, 54, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 12, 12, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 17)                69649     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 17)                0         \n",
      "=================================================================\n",
      "Total params: 46,854,929\n",
      "Trainable params: 46,835,793\n",
      "Non-trainable params: 19,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolution Layer\n",
    "model.add(Conv2D(filters=96, kernel_size=(11,11), input_shape=(224, 224, 3), strides=(4,4), padding='valid'))\n",
    "# Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Activation Function\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling\n",
    "model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "\n",
    "# 2nd Convolution Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "# Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Activation Function\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling\n",
    "model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "\n",
    "# 3rd Convolution Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same'))\n",
    "# Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Activation Function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# 4th Convolution Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), padding='same'))\n",
    "# Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Activation Function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# 5th Convolution Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "# Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Activation Function\n",
    "model.add(Activation('relu'))\n",
    "# Max-Pooling\n",
    "model.add(MaxPooling2D((3,3), strides=(2,2), padding='valid'))\n",
    "\n",
    "\n",
    "# Flattening before passing to the Dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096))\n",
    "# Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Activation Function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "# Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Normalization\n",
    "model.add(BatchNormalization())\n",
    "# Activation Function\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# Output softmax Layer\n",
    "model.add(Dense(17))\n",
    "# Activation Function\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\khand\\anaconda3\\envs\\oldenv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 1088 samples, validate on 272 samples\n",
      "Epoch 1/15\n",
      "1088/1088 [==============================] - 204s 188ms/step - loss: 2.4826 - accuracy: 0.2711 - val_loss: 63.4658 - val_accuracy: 0.1029\n",
      "Epoch 2/15\n",
      "1088/1088 [==============================] - 197s 181ms/step - loss: 1.6757 - accuracy: 0.4596 - val_loss: 36.1013 - val_accuracy: 0.1360\n",
      "Epoch 3/15\n",
      "1088/1088 [==============================] - 229s 210ms/step - loss: 1.2777 - accuracy: 0.5579 - val_loss: 21.1652 - val_accuracy: 0.1471\n",
      "Epoch 4/15\n",
      "1088/1088 [==============================] - 208s 191ms/step - loss: 1.0147 - accuracy: 0.6562 - val_loss: 12.7164 - val_accuracy: 0.2463\n",
      "Epoch 5/15\n",
      "1088/1088 [==============================] - 212s 194ms/step - loss: 0.8449 - accuracy: 0.7105 - val_loss: 8.4507 - val_accuracy: 0.2684\n",
      "Epoch 6/15\n",
      "1088/1088 [==============================] - 225s 207ms/step - loss: 0.7688 - accuracy: 0.7408 - val_loss: 3.6427 - val_accuracy: 0.3235\n",
      "Epoch 7/15\n",
      "1088/1088 [==============================] - 217s 199ms/step - loss: 0.5783 - accuracy: 0.8097 - val_loss: 6.6128 - val_accuracy: 0.2059\n",
      "Epoch 8/15\n",
      "1088/1088 [==============================] - 207s 190ms/step - loss: 0.5519 - accuracy: 0.8171 - val_loss: 9.9424 - val_accuracy: 0.1765\n",
      "Epoch 9/15\n",
      "1088/1088 [==============================] - 203s 187ms/step - loss: 0.4146 - accuracy: 0.8557 - val_loss: 3.1904 - val_accuracy: 0.3713\n",
      "Epoch 10/15\n",
      "1088/1088 [==============================] - 203s 187ms/step - loss: 0.3903 - accuracy: 0.8676 - val_loss: 5.6465 - val_accuracy: 0.2757\n",
      "Epoch 11/15\n",
      "1088/1088 [==============================] - 243s 223ms/step - loss: 0.3434 - accuracy: 0.8888 - val_loss: 2.9977 - val_accuracy: 0.3419\n",
      "Epoch 12/15\n",
      "1088/1088 [==============================] - 206s 190ms/step - loss: 0.3350 - accuracy: 0.8860 - val_loss: 1.6774 - val_accuracy: 0.5956\n",
      "Epoch 13/15\n",
      "1088/1088 [==============================] - 221s 203ms/step - loss: 0.2425 - accuracy: 0.9164 - val_loss: 3.6794 - val_accuracy: 0.4890\n",
      "Epoch 14/15\n",
      "1088/1088 [==============================] - 236s 217ms/step - loss: 0.2039 - accuracy: 0.9320 - val_loss: 2.8484 - val_accuracy: 0.4559\n",
      "Epoch 15/15\n",
      "1088/1088 [==============================] - 218s 201ms/step - loss: 0.1644 - accuracy: 0.9494 - val_loss: 2.0305 - val_accuracy: 0.5551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x218054c82b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training or fitting the model\n",
    "model.fit(X, Y, batch_size=64, epochs=15, verbose=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

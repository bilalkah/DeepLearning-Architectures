{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5 Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://engmrk.com/wp-content/uploads/2018/09/LeNet_Original_Image.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, AvgPool2D, Flatten, Dense\n",
    "from keras.optimizers import Adam \n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset and performing splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the sizes of train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train_x is: (60000, 28, 28)\n",
      "The size of train_y is: (60000,)\n",
      "The size of test_x is: (10000, 28, 28)\n",
      "The size of test_y is: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of train_x is: {}\".format(train_x.shape))\n",
    "print(\"The size of train_y is: {}\".format(train_y.shape))\n",
    "\n",
    "print(\"The size of test_x is: {}\".format(test_x.shape))\n",
    "print(\"The size of test_y is: {}\".format(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the above that the size of mnist image is (28x28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peforming reshaping operations- Converting into 4-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], 28, 28, 1)\n",
    "test_x = test_x.reshape(test_x.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the values corresponding to a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  3]\n",
      "  [ 18]\n",
      "  [ 18]\n",
      "  [ 18]\n",
      "  [126]\n",
      "  [136]\n",
      "  [175]\n",
      "  [ 26]\n",
      "  [166]\n",
      "  [255]\n",
      "  [247]\n",
      "  [127]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 30]\n",
      "  [ 36]\n",
      "  [ 94]\n",
      "  [154]\n",
      "  [170]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [225]\n",
      "  [172]\n",
      "  [253]\n",
      "  [242]\n",
      "  [195]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 49]\n",
      "  [238]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [251]\n",
      "  [ 93]\n",
      "  [ 82]\n",
      "  [ 82]\n",
      "  [ 56]\n",
      "  [ 39]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [219]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [198]\n",
      "  [182]\n",
      "  [247]\n",
      "  [241]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 80]\n",
      "  [156]\n",
      "  [107]\n",
      "  [253]\n",
      "  [253]\n",
      "  [205]\n",
      "  [ 11]\n",
      "  [  0]\n",
      "  [ 43]\n",
      "  [154]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 14]\n",
      "  [  1]\n",
      "  [154]\n",
      "  [253]\n",
      "  [ 90]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [139]\n",
      "  [253]\n",
      "  [190]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 11]\n",
      "  [190]\n",
      "  [253]\n",
      "  [ 70]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 35]\n",
      "  [241]\n",
      "  [225]\n",
      "  [160]\n",
      "  [108]\n",
      "  [  1]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 81]\n",
      "  [240]\n",
      "  [253]\n",
      "  [253]\n",
      "  [119]\n",
      "  [ 25]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 45]\n",
      "  [186]\n",
      "  [253]\n",
      "  [253]\n",
      "  [150]\n",
      "  [ 27]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 16]\n",
      "  [ 93]\n",
      "  [252]\n",
      "  [253]\n",
      "  [187]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [249]\n",
      "  [253]\n",
      "  [249]\n",
      "  [ 64]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 46]\n",
      "  [130]\n",
      "  [183]\n",
      "  [253]\n",
      "  [253]\n",
      "  [207]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 39]\n",
      "  [148]\n",
      "  [229]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [250]\n",
      "  [182]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 24]\n",
      "  [114]\n",
      "  [221]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [201]\n",
      "  [ 78]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 23]\n",
      "  [ 66]\n",
      "  [213]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [198]\n",
      "  [ 81]\n",
      "  [  2]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 18]\n",
      "  [171]\n",
      "  [219]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [195]\n",
      "  [ 80]\n",
      "  [  9]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [ 55]\n",
      "  [172]\n",
      "  [226]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [244]\n",
      "  [133]\n",
      "  [ 11]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [136]\n",
      "  [253]\n",
      "  [253]\n",
      "  [253]\n",
      "  [212]\n",
      "  [135]\n",
      "  [132]\n",
      "  [ 16]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]\n",
      "\n",
      " [[  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]\n",
      "  [  0]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that there are 28 rows and 28 columns and the values in it ranges from 0 to 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see the values of y ranges from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the values of image- converting in between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255.0\n",
    "test_x = test_x/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = to_categorical(train_y, num_classes=10)\n",
    "test_y = to_categorical(test_y, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 44,426\n",
      "Trainable params: 44,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instanciate an empty model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding a Convolution Layer C1\n",
    "# Input shape = N = (28 x 28)\n",
    "# No. of filters  = 6\n",
    "# Filter size = f = (5 x 5)\n",
    "# Padding = P = 0\n",
    "# Strides = S = 1\n",
    "# Size of each feature map in C1 is (N-f+2P)/S +1 = 28-5+1 = 24\n",
    "# No. of parameters between input layer and C1 = (5*5 + 1)*6 = 156\n",
    "model.add(Conv2D(filters=6, kernel_size=(5,5), padding='valid', input_shape=(28,28,1), activation='tanh'))\n",
    "\n",
    "# Adding an Average Pooling Layer S2\n",
    "# Input shape = N = (24 x 24)\n",
    "# No. of filters = 6\n",
    "# Filter size = f = (2 x 2)\n",
    "# Padding = P = 0\n",
    "# Strides = S = 2\n",
    "# Size of each feature map in S2 is (N-f+2P)/S +1 = (24-2+0)/2+1 = 11+1 = 12\n",
    "# No. of parameters between C1 and S2 = (1+1)*6 = 12\n",
    "model.add(AvgPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Adding a Convolution Layer C3\n",
    "# Input shape = N = (12 x 12)\n",
    "# No. of filters  = 16\n",
    "# Filter size = f = (5 x 5)\n",
    "# Padding = P = 0\n",
    "# Strides = S = 1\n",
    "# Size of each feature map in C3 is (N-f+2P)/S +1 = 12-5+1 = 8\n",
    "# No. of parameters between S2 and C3 = (5*5*6*16 + 16) + 16 = 2416\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='tanh'))\n",
    "\n",
    "# Adding an Average Pooling Layer S4\n",
    "# Input shape = N = (8 x 8)\n",
    "# No. of filters = 16\n",
    "# Filter size = f = (2 x 2)\n",
    "# Padding = P = 0\n",
    "# Strides = S = 2\n",
    "# Size of each feature map in S4 is (N-f+2P)/S +1 = (8-2+0)/2+1 = 3+1 = 4\n",
    "# No. of parameters between C3 and S4 = (1+1)*16 = 32\n",
    "model.add(AvgPool2D(pool_size=(2,2)))\n",
    "\n",
    "# As compared to LeNet-5 architecture there was one more application of convolution but in our code  further application of \n",
    "# convolution with (5 x 5) filter would result in a negative dimension which is not possible. So we aren't applying any more\n",
    "# convolution here.\n",
    "\n",
    "# Flattening the layer S4\n",
    "# There would be 16*(4*4) = 256 neurons\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding a Dense layer with `tanh` activation+# \n",
    "# No. of inputs = 256\n",
    "# No. of outputs = 120\n",
    "# No. of parameters = 256*120 + 120 = 30,840\n",
    "model.add(Dense(120, activation='tanh'))\n",
    "\n",
    "# Adding a Dense layer with `tanh` activation\n",
    "# No. of inputs = 120\n",
    "# No. of outputs = 84\n",
    "# No. of parameters = 120*84 + 84 = 10,164\n",
    "model.add(Dense(84, activation='tanh'))\n",
    "\n",
    "# Adding a Dense layer with `softmax` activation\n",
    "# No. of inputs = 84\n",
    "# No. of outputs = 10\n",
    "# No. of parameters = 84*10 + 10 = 850\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 21s 348us/step - loss: 0.3563 - accuracy: 0.8979 - val_loss: 0.1727 - val_accuracy: 0.9467\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 19s 319us/step - loss: 0.1363 - accuracy: 0.9592 - val_loss: 0.1050 - val_accuracy: 0.9679\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 19s 320us/step - loss: 0.0918 - accuracy: 0.9718 - val_loss: 0.0741 - val_accuracy: 0.9775\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.0676 - accuracy: 0.9794 - val_loss: 0.0608 - val_accuracy: 0.9811\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 19s 312us/step - loss: 0.0538 - accuracy: 0.9841 - val_loss: 0.0616 - val_accuracy: 0.9804\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.0472 - val_accuracy: 0.9836\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0372 - accuracy: 0.9885 - val_loss: 0.0535 - val_accuracy: 0.9826\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.0317 - accuracy: 0.9903 - val_loss: 0.0437 - val_accuracy: 0.9850\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0511 - val_accuracy: 0.9837\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 19s 321us/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0479 - val_accuracy: 0.9851\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 19s 324us/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0423 - val_accuracy: 0.9862\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0417 - val_accuracy: 0.9871\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0446 - val_accuracy: 0.9854\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 0.0469 - val_accuracy: 0.9869\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 0.0406 - val_accuracy: 0.9873\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.0100 - accuracy: 0.9969 - val_loss: 0.0416 - val_accuracy: 0.9877\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.0452 - val_accuracy: 0.9864\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.0435 - val_accuracy: 0.9870\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0497 - val_accuracy: 0.9860\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0377 - val_accuracy: 0.9884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ebb0f776d8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size=128, epochs=20, verbose=1, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the loss and accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 196us/step\n",
      "Test Loss: 0.03768365905492028\n",
      "Test accuracy: 0.9883999824523926\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y)\n",
    "\n",
    "print('Test Loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
